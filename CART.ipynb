{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from itertools import chain,combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1,len(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.is_leaf = None\n",
    "        self.splitting_feature = None\n",
    "        self.threshold = None\n",
    "        self.left_set = None\n",
    "        self.right_set = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.gini = None\n",
    "        self.prediction = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self,data,features,target):\n",
    "        self.classes_ = np.unique(data[target])\n",
    "        self.total_data_points = data.shape[0]\n",
    "        self.StrAttrValues_ = {}\n",
    "        for f in features:\n",
    "            if data[f].dtype == np.object:\n",
    "                self.StrAttrValues_[f] = np.unique(data[f])\n",
    "        self.overallgini = 0\n",
    "    def Gini(self,target_values):\n",
    "        if len(target_values) == 0:\n",
    "            return 0\n",
    "        g_a = 0\n",
    "        for c in self.classes_:\n",
    "            prop = np.sum(target_values==c)/len(target_values)\n",
    "            g_a+=prop*prop\n",
    "        return 1-g_a\n",
    "    def create_leaf(self,target_values):\n",
    "        leaf = Node() \n",
    "        leaf.is_leaf = True\n",
    "        leaf.gini = self.Gini(target_values)\n",
    "        self.overallgini += (len(target_values)*leaf.gini)/self.total_data_points\n",
    "        leaf.prediction = stats.mode(target_values)[0][0]               \n",
    "        return leaf \n",
    "    def find_best_split_subset(self,data,feature,StrAttrValues,target_values):\n",
    "        best_gini = 100\n",
    "        left_set,right_set = None,None\n",
    "        subsets = list(powerset(StrAttrValues[feature]))\n",
    "        max_len = len(StrAttrValues[feature])//2\n",
    "        for s in subsets:\n",
    "            set1 = list(s)\n",
    "            if len(s) <= max_len:\n",
    "                set2 = []\n",
    "                for a in StrAttrValues[feature]:\n",
    "                    if a not in set1:\n",
    "                        set2.append(a)\n",
    "                target_values1,target_values2 = target_values[data[feature].isin(set1)],target_values[data[feature].isin(set2)]\n",
    "                if not len(target_values1):\n",
    "                    gini = self.Gini(target_values2)\n",
    "                elif not len(target_values2):\n",
    "                    gini = self.Gini(target_values1)\n",
    "                else:\n",
    "                    gini = (len(target_values1)*self.Gini(target_values1)+len(target_values2)*self.Gini(target_values2))/len(target_values)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    left_set,right_set = set1,set2\n",
    "            else:\n",
    "                break\n",
    "        return (best_gini,left_set,right_set)\n",
    "    def best_threshold(self, data, feature, target_values):\n",
    "        best_gini = 100\n",
    "        threshold = None\n",
    "        num_parent = {}\n",
    "        for c in self.classes_:\n",
    "            num_parent[c] = np.sum(target_values==c)\n",
    "        points, classes = zip(*sorted(zip(data[feature],target_values)))\n",
    "        num_left = {}\n",
    "        for c in self.classes_:\n",
    "            num_left[c] = 0\n",
    "        num_right = num_parent.copy()\n",
    "        m = len(target_values)\n",
    "        for i in range(1,m):\n",
    "            c = classes[i - 1]\n",
    "            num_left[c] += 1\n",
    "            num_right[c] -= 1\n",
    "            gini_left = 1.0 - sum((num_left[x] / i) ** 2 for x in self.classes_)\n",
    "            gini_right = 1.0 - sum((num_right[x] / (m - i)) ** 2 for x in self.classes_)\n",
    "            gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "            if points[i] == points[i - 1]:\n",
    "                continue\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                threshold = (points[i] + points[i - 1]) / 2\n",
    "        return (best_gini,threshold)\n",
    "    def best_splitting_feature(self,data, features, target, StrAttrValues):\n",
    "        best_feature = None \n",
    "        best_gini = 100    \n",
    "        num_data_points = len(data)\n",
    "        threshold = None\n",
    "        left_set,right_set = None,None\n",
    "        for feature in features:\n",
    "            if data[feature].dtype == np.object:\n",
    "                gini,l_set,r_set = self.find_best_split_subset(data,feature,StrAttrValues,data[target])\n",
    "            else:\n",
    "                gini,t = self.best_threshold(data,feature,data[target])\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_feature = feature\n",
    "                if data[best_feature].dtype == np.object:\n",
    "                    left_set,right_set = l_set,r_set\n",
    "                else:\n",
    "                    threshold = t\n",
    "        if data[best_feature].dtype == np.object:\n",
    "            return {'gini':best_gini,'feature':best_feature,'left_set':left_set,'right_set':right_set}\n",
    "        return {'gini':best_gini,'feature':best_feature,'threshold':threshold}\n",
    "    def decision_tree_create(self, data, features, target, current_depth = 0, max_depth = 10,min_data_in_node=0,min_impurity_reduction=-1):\n",
    "        remaining_features = features[:] # Make a copy of the features.\n",
    "        target_values = data[target]\n",
    "        StrAttrValues = self.StrAttrValues_\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "        print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "        if self.Gini(target_values) == 0: \n",
    "            print(\"Stopping condition 1 reached(Pure Node).\")\n",
    "            return self.create_leaf(target_values)\n",
    "        if remaining_features == [] :  \n",
    "            print(\"Stopping condition 2 reached(No feature to split on).\")\n",
    "            return self.create_leaf(target_values)    \n",
    "        if max_depth!= None and current_depth >= max_depth:  \n",
    "            print(\"Early Stopping condition 1(Reached max depth).\")\n",
    "            return self.create_leaf(target_values)\n",
    "        if len(target_values) <= min_data_in_node:\n",
    "            print(\"Early Stopping condition 2(Min Data in Node)).\")\n",
    "            return self.create_leaf(target_values)\n",
    "        split = self.best_splitting_feature(data,remaining_features,target,self.StrAttrValues_)\n",
    "        if split['feature'] == None:\n",
    "            print(\"Creating a leaf(Cannot split further)\")\n",
    "            return self.create_leaf(target_values)\n",
    "        gini_before_split = self.Gini(target_values)\n",
    "        gini_after_split = split['gini']\n",
    "        if gini_before_split-gini_after_split <= min_impurity_reduction:\n",
    "            print(\"Early Stopping condition 3(Min Reduction in impurity)).\")\n",
    "            return self.create_leaf(target_values)\n",
    "        try:\n",
    "            left_split = data[data[split['feature']].isin(split['left_set'])]\n",
    "            right_split = data[data[split['feature']].isin(split['right_set'])]\n",
    "            remaining_features.remove(split['feature'])\n",
    "        except:\n",
    "            left_split = data[data[split['feature']] < split['threshold']]\n",
    "            right_split = data[data[split['feature']] >= split['threshold']]\n",
    "            if len(np.unique(data[split['feature']])) == 2:\n",
    "                remaining_features.remove(split['feature'])\n",
    "        print(f'Split on feature {split[\"feature\"]}. ({len(left_split)},{len(right_split)})')\n",
    "        if len(left_split) == len(data):\n",
    "            print(\"Creating leaf node.\")\n",
    "            return self.create_leaf(left_split[target])\n",
    "        if len(right_split) == len(data):\n",
    "            print(\"Creating leaf node.\")\n",
    "            return self.create_leaf(right_split[target])\n",
    "        left_tree = self.decision_tree_create(left_split, remaining_features, target, current_depth + 1, max_depth,min_data_in_node,min_impurity_reduction)    \n",
    "        right_tree = self.decision_tree_create(right_split, remaining_features, target, current_depth+1, max_depth,min_data_in_node,min_impurity_reduction)\n",
    "        temp = Node()\n",
    "        temp.is_leaf = False\n",
    "        temp.splitting_feature = split['feature']\n",
    "        temp.gini = split['gini']\n",
    "        temp.left,temp.right = left_tree,right_tree\n",
    "        if data[split['feature']].dtype == np.object:\n",
    "            temp.left_set,temp.right_set = split['left_set'],split['right_set']\n",
    "        else:\n",
    "            temp.threshold = split['threshold']\n",
    "        return temp\n",
    "    def classify(self,root, x, annotate = False):   \n",
    "        if root.is_leaf:\n",
    "            if annotate: \n",
    "                print(\"At leaf, predicting %s\" % root.prediction)\n",
    "            return root.prediction\n",
    "        else:\n",
    "            split_feature_value = x[root.splitting_feature]\n",
    "            if annotate: \n",
    "                print(\"Split on %s = %s\" % (root.splitting_feature, split_feature_value))\n",
    "            if type(split_feature_value) == str:\n",
    "                if split_feature_value in root.left_set:\n",
    "                    return self.classify(root.left,x,annotate)\n",
    "                else:\n",
    "                    return self.classify(root.right,x,annotate)\n",
    "            else:\n",
    "                if split_feature_value < root.threshold:\n",
    "                    return self.classify(root.left,x,annotate)\n",
    "                else:\n",
    "                    return self.classify(root.right,x,annotate)\n",
    "    def viewTree(self,root):\n",
    "        print(self.overallgini)\n",
    "        queue = []\n",
    "        queue.append((root,0))\n",
    "        while len(queue):\n",
    "            temp,depth = queue.pop(0)\n",
    "            i = 1\n",
    "            print(f'Depth: {depth} Attribute: {temp.splitting_feature} Gini: {temp.gini}')\n",
    "            if not temp.left.is_leaf:\n",
    "                print(f'[{i}: {temp.left_set if temp.left_set!=None else temp.threshold}: Attribute: {temp.left.splitting_feature}]',end=\"  \")\n",
    "                queue.append((temp.left,depth+1))\n",
    "            else:\n",
    "                print(f'[{i}: {temp.left_set if temp.left_set!=None else temp.threshold}: Class label: {temp.left.prediction}]',end=\"  \")\n",
    "            if not temp.right.is_leaf:\n",
    "                print(f'[{i}: {temp.right_set if temp.right_set!=None else temp.threshold}: Attribute: {temp.right.splitting_feature}]',end=\"  \")\n",
    "                queue.append((temp.right,depth+1))\n",
    "            else:\n",
    "                print(f'[{i}: {temp.right_set if temp.right_set!=None else temp.threshold}: Class label: {temp.right.prediction}]',end=\"  \")\n",
    "            i+=1\n",
    "            print('\\n')\n",
    "    "
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pd.read_csv('bank-additional/bank-additional-full.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       age          job  marital            education  default housing loan  \\\n",
       "0       56    housemaid  married             basic.4y       no      no   no   \n",
       "1       57     services  married          high.school  unknown      no   no   \n",
       "2       37     services  married          high.school       no     yes   no   \n",
       "3       40       admin.  married             basic.6y       no      no   no   \n",
       "4       56     services  married          high.school       no      no  yes   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   73      retired  married  professional.course       no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course       no      no   no   \n",
       "41185   56      retired  married    university.degree       no     yes   no   \n",
       "41186   44   technician  married  professional.course       no      no   no   \n",
       "41187   74      retired  married  professional.course       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "0      telephone   may         mon  ...         1    999         0   \n",
       "1      telephone   may         mon  ...         1    999         0   \n",
       "2      telephone   may         mon  ...         1    999         0   \n",
       "3      telephone   may         mon  ...         1    999         0   \n",
       "4      telephone   may         mon  ...         1    999         0   \n",
       "...          ...   ...         ...  ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri  ...         1    999         0   \n",
       "41184   cellular   nov         fri  ...         1    999         0   \n",
       "41185   cellular   nov         fri  ...         2    999         0   \n",
       "41186   cellular   nov         fri  ...         1    999         0   \n",
       "41187   cellular   nov         fri  ...         3    999         1   \n",
       "\n",
       "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "4      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "...            ...          ...             ...            ...        ...   \n",
       "41183  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41184  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41185  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41186  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41187      failure         -1.1          94.767          -50.8      1.028   \n",
       "\n",
       "       nr.employed    y  \n",
       "0           5191.0   no  \n",
       "1           5191.0   no  \n",
       "2           5191.0   no  \n",
       "3           5191.0   no  \n",
       "4           5191.0   no  \n",
       "...            ...  ...  \n",
       "41183       4963.6  yes  \n",
       "41184       4963.6   no  \n",
       "41185       4963.6   no  \n",
       "41186       4963.6  yes  \n",
       "41187       4963.6   no  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>basic.4y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>basic.6y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41183</th>\n      <td>73</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>41184</th>\n      <td>46</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>41185</th>\n      <td>56</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>university.degree</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>41186</th>\n      <td>44</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>41187</th>\n      <td>74</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>3</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>41188 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(bank,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-94-001516fa8bbe>:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train[c] = le.transform(train[c])\n<ipython-input-94-001516fa8bbe>:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test[c] = le.transform(test[c])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for c in train.columns[:-1]:\n",
    "    if train[c].dtype == np.object:\n",
    "        le.fit(train[c])\n",
    "        train[c] = le.transform(train[c])\n",
    "        test[c] = le.transform(test[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = bank.columns.to_list()[:-1]\n",
    "target = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = CART(train,features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (32950 data points).\n",
      "Split on feature nr.employed. (3997,28953)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (3997 data points).\n",
      "Split on feature duration. (1392,2605)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1392 data points).\n",
      "Split on feature pdays. (216,1176)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (216 data points).\n",
      "Split on feature day_of_week. (93,123)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (93 data points).\n",
      "Split on feature cons.price.idx. (63,30)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (63 data points).\n",
      "Split on feature campaign. (52,11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (52 data points).\n",
      "Split on feature duration. (9,43)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (9 data points).\n",
      "Stopping condition 1 reached(Pure Node).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (43 data points).\n",
      "Early Stopping condition 1(Reached max depth).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Stopping condition 1 reached(Pure Node).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (30 data points).\n",
      "Early Stopping condition 2(Min Data in Node)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (123 data points).\n",
      "Split on feature euribor3m. (34,89)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Early Stopping condition 2(Min Data in Node)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (89 data points).\n",
      "Split on feature duration. (70,19)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (70 data points).\n",
      "Split on feature cons.price.idx. (54,16)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (54 data points).\n",
      "Early Stopping condition 1(Reached max depth).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (16 data points).\n",
      "Early Stopping condition 1(Reached max depth).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (19 data points).\n",
      "Early Stopping condition 2(Min Data in Node)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1176 data points).\n",
      "Early Stopping condition 3(Min Reduction in impurity)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2605 data points).\n",
      "Split on feature pdays. (742,1863)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (742 data points).\n",
      "Early Stopping condition 3(Min Reduction in impurity)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1863 data points).\n",
      "Split on feature duration. (693,1170)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (693 data points).\n",
      "Early Stopping condition 3(Min Reduction in impurity)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1170 data points).\n",
      "Early Stopping condition 3(Min Reduction in impurity)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28953 data points).\n",
      "Split on feature duration. (25805,3148)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (25805 data points).\n",
      "Early Stopping condition 3(Min Reduction in impurity)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3148 data points).\n",
      "Split on feature duration. (2044,1104)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2044 data points).\n",
      "Split on feature euribor3m. (370,1674)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (370 data points).\n",
      "Split on feature euribor3m. (328,42)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (328 data points).\n",
      "Split on feature duration. (112,216)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (112 data points).\n",
      "Split on feature poutcome. (29,83)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (29 data points).\n",
      "Early Stopping condition 1(Reached max depth).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (83 data points).\n",
      "Early Stopping condition 1(Reached max depth).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (216 data points).\n",
      "Split on feature default. (169,47)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (169 data points).\n",
      "Early Stopping condition 1(Reached max depth).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (47 data points).\n",
      "Early Stopping condition 1(Reached max depth).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (42 data points).\n",
      "Split on feature education. (40,2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (40 data points).\n",
      "Early Stopping condition 2(Min Data in Node)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached(Pure Node).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1674 data points).\n",
      "Early Stopping condition 3(Min Reduction in impurity)).\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1104 data points).\n",
      "Early Stopping condition 3(Min Reduction in impurity)).\n"
     ]
    }
   ],
   "source": [
    "root = tree.decision_tree_create(train,features,target,0,7,40,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12472025700740622\nDepth: 0 Attribute: nr.employed Gini: 0.17030160025393262\n[1: 5087.65: Attribute: duration]  [1: 5087.65: Attribute: duration]  \n\nDepth: 1 Attribute: duration Gini: 0.4028072959489401\n[1: 158.5: Attribute: pdays]  [1: 158.5: Attribute: pdays]  \n\nDepth: 1 Attribute: duration Gini: 0.09813637262062751\n[1: 524.5: Class label: no]  [1: 524.5: Attribute: duration]  \n\nDepth: 2 Attribute: pdays Gini: 0.24247386534434967\n[1: 14.5: Attribute: day_of_week]  [1: 14.5: Class label: no]  \n\nDepth: 2 Attribute: pdays Gini: 0.44077016108694106\n[1: 16.5: Class label: yes]  [1: 16.5: Attribute: duration]  \n\nDepth: 2 Attribute: duration Gini: 0.45307370223461285\n[1: 835.5: Attribute: euribor3m]  [1: 835.5: Class label: yes]  \n\nDepth: 3 Attribute: day_of_week Gini: 0.41288574176064335\n[1: 1.5: Attribute: cons.price.idx]  [1: 1.5: Attribute: euribor3m]  \n\nDepth: 3 Attribute: duration Gini: 0.4807174456127758\n[1: 250.5: Class label: no]  [1: 250.5: Class label: yes]  \n\nDepth: 3 Attribute: euribor3m Gini: 0.416921207553112\n[1: 1.3885: Attribute: euribor3m]  [1: 1.3885: Class label: no]  \n\nDepth: 4 Attribute: cons.price.idx Gini: 0.27748762587472275\n[1: 93.559: Attribute: campaign]  [1: 93.559: Class label: no]  \n\nDepth: 4 Attribute: euribor3m Gini: 0.43710068296981713\n[1: 0.7155: Class label: yes]  [1: 0.7155: Attribute: duration]  \n\nDepth: 4 Attribute: euribor3m Gini: 0.46334479078381513\n[1: 1.3490000000000002: Attribute: duration]  [1: 1.3490000000000002: Attribute: education]  \n\nDepth: 5 Attribute: campaign Gini: 0.3516483516483517\n[1: 2.5: Attribute: duration]  [1: 2.5: Class label: no]  \n\nDepth: 5 Attribute: duration Gini: 0.42968657599053817\n[1: 138.5: Attribute: cons.price.idx]  [1: 138.5: Class label: yes]  \n\nDepth: 5 Attribute: duration Gini: 0.4798945831720222\n[1: 593.5: Attribute: poutcome]  [1: 593.5: Attribute: default]  \n\nDepth: 5 Attribute: education Gini: 0.13214285714285706\n[1: 6.5: Class label: yes]  [1: 6.5: Class label: no]  \n\nDepth: 6 Attribute: duration Gini: 0.38640429338103754\n[1: 90.0: Class label: no]  [1: 90.0: Class label: no]  \n\nDepth: 6 Attribute: cons.price.idx Gini: 0.38657407407407407\n[1: 94.041: Class label: no]  [1: 94.041: Class label: no]  \n\nDepth: 6 Attribute: poutcome Gini: 0.4064632915900053\n[1: 0.5: Class label: no]  [1: 0.5: Class label: no]  \n\nDepth: 6 Attribute: default Gini: 0.4667608562862245\n[1: 0.5: Class label: yes]  [1: 0.5: Class label: no]  \n\n"
     ]
    }
   ],
   "source": [
    "tree.viewTree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(true_y,pred_y):\n",
    "    return sum(true_y == pred_y)/len(pred_y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = []\n",
    "test_x = test.iloc[:,:-1]\n",
    "for i in test_x.index:\n",
    "    pred_y.append(tree.classify(root,test_x.loc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "92.0004855547463"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "accuracy(test.iloc[:,-1].values,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}